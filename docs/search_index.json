[
["manip.html", "3 Manipular 3.1 select 3.2 filter 3.3 mutate 3.4 arrange 3.5 summarise 3.6 Dataset “canola” 3.7 Extra: casualizar unidades experimentais", " 3 Manipular Muchas veces los datos que importamos ya están listos para ser explorados y analizados. Otras veces precisan ser manipulados previamente para ello. En estos casos se parte de un dataset “crudo” y se transforma hacia un dataset analítico. Recordando que un dataset debe ser completo con dimensiones n_fila x n_columna, donde: 1- Cada fila debe contener toda la info de la unidad experimental que se está evaluando 2- Cada columna representa una variable (descriptiva o respuesta). 3- Cada celda debe tener su observación (en caso de faltar el dato será un NA) tidyr y dplyr son paquetes que facilitan la manipulación de los datasets y son parte de la colección de paquetes de tidyverse library(tidyverse) Ambos paquetes hacen uso de las facilidades del operador %&gt;% (pipe, tubo en español) lo que facilita su interpretación lógica: utiliza el resultado de su lado izquierdo como primer argumento de la función del lado derecho (asemejandose a una receta de torta…) x &lt;- c(1, 2, 3, 4) x %&gt;% sum %&gt;% sqrt Su equivalente de código básico es: sqrt(sum(x)) Importemos los datos “soja” para ver alguno ejemplos. Red de ensayos de fungicidas para el control de mancha anillada en soja soy &lt;- readr::read_csv(&quot;data/soja_mancha.csv&quot;) soy # browseURL(&quot;https://osf.io/jpfet/&quot;) Describa el dataset. study: identificador arbitrario para cada experimento year: año del experimento location: localidad do experimento cultivar: cultivar de soja utilizado fungic: tratamiento fungicida block: repeticiones sev: severidad (%) evaluada en R6 yield: rendimiento en madurez fisiológica (kg/ha) Los cinco verbos (funciones) principales de dplyr son: filter - filtra líneas (idem excel) mutate - crea nuevas variables agregandose a las columnas existentes en nuestro dataset arrange - ordena la base con algun criterio especificado summarise - aplica una operacion matemática indicada Primero vamos a explorar el dataset que acabamos de importar: summary(soy) str(soy) Haremos que las variables tipo caracter sean convertidas a factores: soy &lt;- soy %&gt;% mutate_if(is.character, as.factor) summary(soy) str(soy) 3.1 select Vamos a seleccionar las variables: study, year, cultivar, fungic, rep, sev y yield. soy %&gt;% select(study, year, cultivar, fungic, rep, sev, yield) Es posible usar intervalos de varibles con :. Una selección “negativa” de las variables no deseadas daría un mismo resultado: soy %&gt;% select(-Yld_level, -YR_class, -gr_hab, -sev_check) 3.2 filter Semejante a subset. Condiciones separadas por comas equivalen a &amp; de subset. Filtremos la variable fungicida (fungic) por el testigo (ZZ_CHECK) soy %&gt;% select(study:yield) %&gt;% filter(fungic == &#39;ZZ_CHECK&#39;) Ahora, agreguemos el fungicida carbendazim a dosis de 1 litro (CZM[1]) al dataset soy %&gt;% select(study:yield) %&gt;% filter(fungic %in% c(&quot;ZZ_CHECK&quot;,&quot;CZM&quot;)) 3.3 mutate Creación de nuevas variables (a partir de las existentes) Muchas variables biológicas no cumplen con los supuestos de las pruebas estadísticas paramétricas: no se distribuyen normalmente, las desviaciones estándar no son homogéneas, o ambas. Hay extensa bibliografia al respecto, recomendando cual transformación es la más adecuada para cada tipo de variable y asi poder ser analizada por un ANOVA tradicional (paramétrico). Como fitopatólogos, la no normalidad es lo predominante. El caso mas común es la severidad de enfermedades que comparamos a través de diferentes tratamientos (cultivar, fungicida, practica de manejo, etc.) Dos transformaciones son mayormente sugeridas para la severidad: Transformacion Arcsine:consiste en tomar el arcoseno de la raiz cuadrada de un numero. (El resultado está dado en radianes, no grados, con unrango de −π/2 a π/2.) Transformación logit: soy1 &lt;- soy %&gt;% select(study:yield) %&gt;% filter(fungic %in% c(&quot;ZZ_CHECK&quot;,&quot;CZM&quot;)) %&gt;% mutate(sev_arc = asin(sqrt(sev/100)), sev_logit = car::logit(sev, percents=TRUE),# log(sev/100/(1-sev/100)), # yield_tn = yield/1000) # browseURL(&quot;http://strata.uga.edu/8370/rtips/proportions.html&quot;) 3.4 arrange Ordena crecientemente de acuerdo a la columna que le indiquemos. Utilizar “desc”&quot; para ordem decrescente. soy1 %&gt;% arrange(year, cultivar) soy1 %&gt;% arrange(year, desc(cultivar)) 3.5 summarise Generalmente acompañada de la función group_by la cual permite aplicar un cálculo a las observaciones agrupando por niveles de algún factor (equivale a una tabla dinámica de excel) Veamos cuanto fue el rendimiento promedio y el desvio standard para cada fungicida a través de todos los ensayos: soy %&gt;% group_by(fungic) %&gt;% summarise(yield_mean = mean(yield), yield_sd = sd(yield)) Calculen el rendimiento mínimo y máximo por fungicida Algunas funciones interesantes para la descripción del dataset: n(), n_distinct(). Cuantos ensayos fueron realizados por año: soy %&gt;% group_by(year) %&gt;% summarize(n = n_distinct(study)) Cuantas parcelas tenia cada ensayo y cual fue la severdiad máxima en cada um deles: soy %&gt;% group_by(study, year, cultivar) %&gt;% summarize(plots = n()) Note que agora desejamos manter o resto das variaveis descritivas dos ensaios, por isso alem do “study” escrevemos group_by(study, year, state, location, cultivar) (Típica tabela de descrição de ensaios para artigos ou teses) Adicione a coluna potencial de rendimento (rend_pot), considerando o maximo rendimento observado. Crie as seguintes tabelas: i) by_location, detalhando de ordem decrescente quantos ensaios foram realizados em cada local; ii) by_cultivar; iii) by_fungicide. Crie uma tabela “by_check” calculando a média da severidade no “CHECK” (sev_check). Usando a função ifelse crie uma nova variavel categórica “pressão de doença”&quot; considerando a “sev_check”: Low ou High by_check = soy %&gt;% filter(fungic==&quot;CHECK&quot;) %&gt;% group_by(study) %&gt;% summarize(sev_check = round(mean(sev, na.rm = TRUE),1)) %&gt;% mutate(Dis_level = ifelse(sev_check &lt; 30, &quot;Low&quot;, &quot;High&quot;))) Funções auxiliares join junta dois data.frames através de pontos em comun. Por exemplo, se queremos anexar as variáveis “sev_check” e “Dis_level” para o banco de dados completo: soy %&gt;% full_join(by_check, by=&quot;study&quot;) Crie as variaveis “dif_sev” e “dif_yield”, de cada plot respeito aos checks. 3.6 Dataset “canola” canola Isto seria uma forma “wide” de representação do dataset (cru). Para analisar o efeito do tratemento fungicida precisamos calcular a área abaixo da curva (AUC) do progresso da doença. Para isto precissamos passar ao formato “long”. A função gather (do inglês “reunir”, pacote tidyr) empilha as colunas que desejemos. # criaremos uma variavel &quot;tt&quot; com os nomes das colunas com numeros, # e outra &quot;incp&quot; (incidencia em proporção) com os valores correspondientes. can_long &lt;- canola %&gt;% gather(`015`, `058`, `095`, `146`, `165`, `180`, `248`, key = &quot;tt&quot;, value = &quot;incp&quot;) # gather(tt, incp, -c(par:bk)) ;) #save(canola, can_long, file = &quot;canolass.RData&quot;) can_long # Precisamos que tt seja classe &quot;numeric&quot; para certos calculos can_long$tt &lt;- as.numeric(can_long$tt) Precissamos de um valor de AUC por parcela. Vamos a fazer isso com auxilio das funções group_by summarize mutate_each_ do pacote dplyr e separate do pacote tidyr. Notese tambem podem ser usados funções de outros pacotes, como será usada a função aucdo pacote MESS, que calcula a AUC simplesmente assim auc(x, y, type = &quot;spline&quot;). Como o pacote MESSsó será usado uma vez nesta sessão não é necessário ativar ele com library(), simplesmente colocando MESS:: ele será usado unicamente neste bloco de código. auc &lt;- can_long %&gt;% group_by(par) %&gt;% summarize(AUC = MESS::auc(tt, incp, type = &quot;spline&quot;)) %&gt;% separate(par, into= c(&quot;bk&quot;, &quot;trt&quot;), sep=1) %&gt;% mutate_each_(funs(factor), c(&quot;bk&quot;,&quot;trt&quot;)) Agora sim, canola está pronto para entrar ao próximo passo: modelado. 3.7 Extra: casualizar unidades experimentais library(agricolae) # Complete Randomized Design trt &lt;- c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;) repeticion &lt;- 4 DIC &lt;- design.crd(trt, r=repeticion, seed=0, serie=0) (planilha_dic &lt;- DIC$book) # Randomized Complete Block Design trt &lt;- LETTERS[1:20] rep &lt;- 5 DBCA &lt;- design.rcbd(trt, r=rep, first=FALSE, seed=111, kinds = &quot;Super-Duper&quot;, serie=2) (planilha_DBCA &lt;- DBCA$book) planilha_DBCA2&lt;- zigzag(DBCA) # zigzag numeration print(DBCA$sketch) write_csv(planilha_DBCA2, &quot;campo.csv&quot;) # split-plot design t1&lt;-c(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;,&quot;D&quot;) t2&lt;-c(1,2,3) split &lt;-design.split(t1, t2, r=3, serie=2, seed=45, kinds=&quot;Super-Duper&quot;)#seed=45 (planilha_split &lt;-split$book) # field book References R for data science. Garrett Grolemund &amp; Hadley Wickham. Online: http://r4ds.had.co.nz/ Curso de R do Instituto de Matemática e Estatística da Universidade de São Paulo (IME-USP) Online: http://curso-r.com "]
]
